[
  {"question": "What is the price of the new RTX 5070?", "answer": "$549", "difficulty": "easy", "avg_score": "98.0", "worst_score": "90", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "The price of the new RTX 5070 is $549.", "model": "deepseek-chat"}, {"question": "Which architecture does the new GeForce RTX 50 Series use?", "answer": "The Blackwell architecture", "difficulty": "easy", "avg_score": "99.0", "worst_score": "95", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "The new GeForce RTX 50 Series uses the **Blackwell architecture**.", "model": "deepseek-chat"}, {"question": "How does the RTX 5070 compare in performance to the RTX 4090?", "answer": "It matches the performance of the RTX 4090", "difficulty": "easy", "avg_score": "85.0", "worst_score": "85", "best_score": "85", "acceptable_score": "100.00%", "best_answer": "The RTX 5070 offers performance comparable to the RTX 4090, as mentioned in the context, with the RTX 5070 delivering 4090-level performance at a lower price point of $549. Additionally, the RTX 5090, part of the same Blackwell family, is stated to have twice the performance of the RTX 4090.", "model": "deepseek-chat"}, {"question": "What is the approximate retail price for a laptop featuring the RTX 5070?", "answer": "$1,299", "difficulty": "easy", "avg_score": "94.0", "worst_score": "90", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "The approximate retail price for a laptop featuring the RTX 5070 is $1,299.", "model": "deepseek-chat"}, {"question": "How many additional frames can the latest generation of DLSS predict for each rendered frame?", "answer": "It can predict three additional frames for every frame rendered", "difficulty": "easy", "avg_score": "98.0", "worst_score": "95", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "The latest generation of DLSS can predict three additional frames for every rendered frame. This allows for higher performance by generating more frames with less computational effort.", "model": "deepseek-chat"}, {"question": "What is the memory bandwidth of the GeForce RTX 50 Series GPUs\u2019 G7 memory?", "answer": "1.8 terabytes per second", "difficulty": "easy", "avg_score": "100.0", "worst_score": "100", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "The memory bandwidth of the GeForce RTX 50 Series GPUs\u2019 G7 memory is **1.8 terabytes per second**. This is twice the performance of the previous generation.", "model": "deepseek-chat"}, {"question": "Name one of the AI models mentioned that can generate 3D images from textual prompts.", "answer": "Flux (an image generation NeMo)", "difficulty": "easy", "avg_score": "72.0", "worst_score": "20", "best_score": "85", "acceptable_score": "80.00%", "best_answer": "One of the AI models mentioned that can generate 3D images from textual prompts is **NVIDIA Cosmos**. It ingests text, image, or video prompts to generate virtual world states as videos, prioritizing real-world environments and lighting.", "model": "deepseek-chat"}, {"question": "Which NVIDIA platform is used to help develop domain-specific AI agents for enterprise use?", "answer": "NVIDIA NeMo", "difficulty": "easy", "avg_score": "97.0", "worst_score": "95", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "The NVIDIA platform used to help develop domain-specific AI agents for enterprise use is **NVIDIA NeMo**. It provides AI microservices and frameworks that enable organizations to easily create and deploy AI agents tailored to specific tasks.", "model": "deepseek-chat"}, {"question": "What major change did Google's Transformer bring to AI according to the keynote?", "answer": "It completely changed the landscape for artificial intelligence and computing", "difficulty": "easy", "avg_score": "95.0", "worst_score": "95", "best_score": "95", "acceptable_score": "100.00%", "best_answer": "Google's Transformer, released as BERT in 2018, fundamentally changed the landscape of artificial intelligence and computing. It enabled machine learning to revolutionize how computing works, shifting from traditional hand-coded instructions to AI-driven processes that optimize networks and create intelligence. This transformation marked a significant leap in AI capabilities and applications.", "model": "deepseek-chat"}, {"question": "What is the code name of NVIDIA\u2019s new world foundation model for physical AI?", "answer": "NVIDIA Cosmos", "difficulty": "easy", "avg_score": "95.0", "worst_score": "95", "best_score": "95", "acceptable_score": "100.00%", "best_answer": "The code name of NVIDIA\u2019s new world foundation model for physical AI is **NVIDIA Cosmos**. It is designed to understand the physical world and is trained on 20 million hours of video focusing on physical dynamics.", "model": "deepseek-chat"}, {"question": "Which technology helps reduce the computational load by generating unrendered pixels using AI?", "answer": "DLSS (Deep Learning Super Sampling)", "difficulty": "easy", "avg_score": "100.0", "worst_score": "100", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "The technology that helps reduce the computational load by generating unrendered pixels using AI is **DLSS (Deep Learning Super Sampling)**. DLSS uses AI to predict and generate pixels that were not rendered, significantly improving performance and efficiency.", "model": "deepseek-chat"}, {"question": "How many transistors does the Blackwell GPU in the RTX 50 Series have?", "answer": "92 billion transistors", "difficulty": "medium", "avg_score": "100.0", "worst_score": "100", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "The Blackwell GPU in the RTX 50 Series has 92 billion transistors.", "model": "deepseek-chat"}, {"question": "What is the name of NVIDIA\u2019s next-generation robotics computer announced in the keynote?", "answer": "Thor", "difficulty": "medium", "avg_score": "99.0", "worst_score": "95", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "The name of NVIDIA\u2019s next-generation robotics computer announced in the keynote is **Thor**. It is described as a universal robotics computer with significant processing capabilities.", "model": "deepseek-chat"}, {"question": "What is the function of post-training scaling mentioned in the keynote?", "answer": "It involves techniques like reinforcement learning and human feedback to refine AI after its initial training", "difficulty": "medium", "avg_score": "94.0", "worst_score": "90", "best_score": "95", "acceptable_score": "100.00%", "best_answer": "The function of post-training scaling is to improve AI models using techniques like reinforcement learning and human feedback. It involves the AI generating answers based on human queries, receiving feedback, and iteratively improving its performance. This process requires significant computation but results in highly capable models.", "model": "deepseek-chat"}, {"question": "Which automotive company did Jensen mention as a new partner for developing next-generation AVs with NVIDIA?", "answer": "Toyota", "difficulty": "medium", "avg_score": "100.0", "worst_score": "100", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "Jensen mentioned Toyota as the new partner for developing next-generation autonomous vehicles (AVs) with NVIDIA.", "model": "deepseek-chat"}, {"question": "What is the main focus of NVIDIA Isaac GrOot in robotics development?", "answer": "It provides tools and workflows for synthetic data generation, imitation learning, and policy training for humanoid robots", "difficulty": "medium", "avg_score": "89.0", "worst_score": "85", "best_score": "90", "acceptable_score": "100.00%", "best_answer": "The main focus of NVIDIA Isaac GrOot in robotics development is to accelerate the development of general robotics by providing a technology platform that includes robot foundation models, data pipelines, simulation frameworks, and a Thor robotics computer. It enables developers to generate large datasets for training robots through imitation learning and synthetic data generation.", "model": "deepseek-chat"}, {"question": "What are the three computers that NVIDIA says every robotics company will need?", "answer": "A DGX for training AI models, Omniverse/Cosmos for simulation, and an AGX (like Thor) in the robot or autonomous system", "difficulty": "medium", "avg_score": "95.0", "worst_score": "95", "best_score": "95", "acceptable_score": "100.00%", "best_answer": "The three computers that NVIDIA says every robotics company will need are:  \n1. **NVIDIA DGX** to train AI models,  \n2. **Omniverse** to test, drive, and generate synthetic data, and  \n3. **DRIVE AGX**, a supercomputer in the car or robot for deployment.", "model": "deepseek-chat"}, {"question": "Why is synthetic data so crucial for training autonomous vehicles according to the keynote?", "answer": "Real-world data is limited and costly to capture; synthetic data can amplify edge cases and help train at massive scale", "difficulty": "medium", "avg_score": "95.0", "worst_score": "95", "best_score": "95", "acceptable_score": "100.00%", "best_answer": "Synthetic data is crucial for training autonomous vehicles because it allows for the generation of diverse and complex driving scenarios, including edge cases, which are difficult to capture with real-world data alone. NVIDIA's tools, like Omniverse and Cosmos, create high-fidelity, physically accurate simulations that amplify training data by orders of magnitude, enabling safer and more advanced autonomous driving systems. This approach ensures a vast amount of training data, essential for improving AI models in autonomous vehicles.", "model": "deepseek-chat"}, {"question": "What kind of new AI era does Jensen predict is approaching for enterprise applications?", "answer": "Agentic AI, where multiple AI models collaborate, plan, and take actions on behalf of users", "difficulty": "medium", "avg_score": "93.0", "worst_score": "90", "best_score": "95", "acceptable_score": "100.00%", "best_answer": "Jensen predicts that the new AI era approaching for enterprise applications is **Agentic AI**, which refers to AI systems that can perceive, reason, plan, and act. This era is characterized by AI models that work in the background to solve complex problems and enable new capabilities for enterprises.", "model": "deepseek-chat"}, {"question": "Which core idea makes Omniverse critical for physically accurate simulation?", "answer": "It is a physics-principled simulation platform, grounded in real-world principles like friction, lighting, and object permanence", "difficulty": "medium", "avg_score": "91.0", "worst_score": "90", "best_score": "95", "acceptable_score": "100.00%", "best_answer": "The core idea that makes Omniverse critical for physically accurate simulation is its foundation as a **physics-principled, physics simulation grounded system**. It provides the ground truth and controls the generation of synthetic data, ensuring simulations are physically grounded and accurate. This capability is essential for applications like autonomous vehicles and robotics.", "model": "deepseek-chat"}, {"question": "What is NVIDIA\u2019s stated reason for making Llama 2 NeoTron models available?", "answer": "To provide enterprise-focused models with improved fine-tuning and performance for domains like chat, instruction, and retrieval", "difficulty": "hard", "avg_score": "86.0", "worst_score": "85", "best_score": "90", "acceptable_score": "100.00%", "best_answer": "NVIDIA made Llama 2 NeoTron models available because they realized the Llama models could be better fine-tuned for enterprise use. They fine-tuned these models using their expertise and capabilities to create the Llama 2 NeoTron suite, which includes small, fast-response models optimized for enterprise applications.", "model": "deepseek-chat"}, {"question": "Name two techniques mentioned that allow AI models to refine themselves after initial training.", "answer": "Reinforcement learning with human feedback and synthetic data generation", "difficulty": "hard", "avg_score": "86.0", "worst_score": "85", "best_score": "90", "acceptable_score": "100.00%", "best_answer": "Two techniques mentioned for refining AI models after initial training are **reinforcement learning** and **synthetic data generation**. Reinforcement learning involves the AI improving through feedback, while synthetic data generation creates diverse scenarios for further training.", "model": "deepseek-chat"}, {"question": "How much performance gain, in terms of perf per watt, does the Blackwell-based datacenter system have over the previous generation?", "answer": "It is roughly four times more performance per watt than the previous generation", "difficulty": "hard", "avg_score": "100.0", "worst_score": "100", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "The Blackwell-based datacenter system has a performance gain of four times in terms of perf per watt compared to the previous generation.", "model": "deepseek-chat"}, {"question": "Approximately how large is the total memory in NVIDIA\u2019s \u2018giant chip\u2019 multi-GPU configuration described in the keynote?", "answer": "About 14 terabytes of memory", "difficulty": "hard", "avg_score": "99.0", "worst_score": "95", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "The total memory in NVIDIA\u2019s \u2018giant chip\u2019 multi-GPU configuration is approximately 14 terabytes of HBM memory. This is part of the Blackwell system, which is described as having 14 terabytes of memory.", "model": "deepseek-chat"}, {"question": "Which industry does Jensen predict will be the first multi-trillion-dollar robotics market?", "answer": "Autonomous vehicles (AVs)", "difficulty": "hard", "avg_score": "100.0", "worst_score": "100", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "Jensen predicts that the autonomous vehicle industry will be the first multi-trillion-dollar robotics market. This includes self-driving cars and trucks, which are expected to become highly or fully autonomous in the near future.", "model": "deepseek-chat"}, {"question": "What does test-time scaling in AI primarily involve?", "answer": "Allocating more or different amounts of compute during inference, often for multi-step reasoning or chain-of-thought processes", "difficulty": "hard", "avg_score": "95.0", "worst_score": "95", "best_score": "95", "acceptable_score": "100.00%", "best_answer": "Test-time scaling in AI primarily involves the AI dynamically allocating computational resources to produce answers, rather than improving its parameters. It focuses on deciding how much computation to use for tasks like reasoning, breaking down problems, and generating multiple ideas to evaluate the best solution. This approach enhances the AI's ability to provide more accurate and contextually relevant responses.", "model": "deepseek-chat"}, {"question": "What is the significance of NVIDIA\u2019s Drive OS reaching ASIL D certification?", "answer": "It is the highest functional safety standard, making NVIDIA\u2019s AI computer software-defined yet safety-certified for cars", "difficulty": "hard", "avg_score": "95.0", "worst_score": "95", "best_score": "95", "acceptable_score": "100.00%", "best_answer": "NVIDIA\u2019s Drive OS reaching ASIL D certification is significant because it is the highest standard of functional safety for automobiles, ensuring the system meets rigorous safety requirements for autonomous driving. This certification highlights NVIDIA's commitment to safety and positions Drive OS as a leading software-defined, programmable AI computer for the automotive industry. It represents the culmination of extensive engineering efforts, equivalent to 15,000 engineering years.", "model": "deepseek-chat"}, {"question": "Which specific memory technology is used in the Grace Hopper-based \u2018smallest chip\u2019 for the newly unveiled Project Digits system?", "answer": "HBM (High Bandwidth Memory), connected with chip-to-chip NVLink", "difficulty": "hard", "avg_score": "95.0", "worst_score": "95", "best_score": "95", "acceptable_score": "100.00%", "best_answer": "The Grace Hopper-based \u2018smallest chip\u2019 for the newly unveiled Project Digits system uses **HBM (High Bandwidth Memory)** technology. This is evidenced by the mention of \"14 terabytes of HBM memory\" in the context.", "model": "deepseek-chat"}, {"question": "How many hours of video was Cosmos trained on to understand physical dynamics?", "answer": "20 million hours of video", "difficulty": "hard", "avg_score": "100.0", "worst_score": "100", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "NVIDIA Cosmos was trained on **20 million hours of video** to understand physical dynamics. This training focused on capturing physical movements, such as humans walking, hands manipulating objects, and fast camera movements.", "model": "deepseek-chat"}, {"question": "Why is WSL2 (Windows Subsystem for Linux 2) important for AI on Windows PCs according to the keynote?", "answer": "It gives direct access to CUDA out of the box, enabling cloud-native AI workflows and NVIDIA's entire AI software stack on Windows", "difficulty": "hard", "avg_score": "88.0", "worst_score": "85", "best_score": "95", "acceptable_score": "100.00%", "best_answer": "WSL2 is important for AI on Windows PCs because it allows Windows PCs to function as a first-class platform for AI development, supporting CUDA perfectly out of the box. This optimization enables seamless integration of AI models, such as NVIDIA NeMo, and ensures that developers can run cloud-native and CUDA-optimized applications efficiently on Windows PCs.", "model": "deepseek-chat"}
]