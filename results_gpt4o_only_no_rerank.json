[
  {"question": "What is the price of the new RTX 5070?", "answer": "$549", "difficulty": "easy", "avg_score": "100.0", "worst_score": "100", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "The price of the new RTX 5070 is $549.", "model": "gpt-4o"}, {"question": "Which architecture does the new GeForce RTX 50 Series use?", "answer": "The Blackwell architecture", "difficulty": "easy", "avg_score": "100.0", "worst_score": "100", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "The new GeForce RTX 50 Series uses the Blackwell architecture.", "model": "gpt-4o"}, {"question": "How does the RTX 5070 compare in performance to the RTX 4090?", "answer": "It matches the performance of the RTX 4090", "difficulty": "easy", "avg_score": "87.0", "worst_score": "85", "best_score": "95", "acceptable_score": "100.00%", "best_answer": "The RTX 5070 is stated to have the performance of the RTX 4090 at a lower price point of $549. This suggests that the RTX 5070 offers similar performance capabilities to the 4090, making it a more cost-effective option.", "model": "gpt-4o"}, {"question": "What is the approximate retail price for a laptop featuring the RTX 5070?", "answer": "$1,299", "difficulty": "easy", "avg_score": "100.0", "worst_score": "100", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "The approximate retail price for a laptop featuring the RTX 5070 is $1,299.", "model": "gpt-4o"}, {"question": "How many additional frames can the latest generation of DLSS predict for each rendered frame?", "answer": "It can predict three additional frames for every frame rendered", "difficulty": "easy", "avg_score": "100.0", "worst_score": "100", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "The latest generation of DLSS can predict three additional frames for each rendered frame.", "model": "gpt-4o"}, {"question": "What is the memory bandwidth of the GeForce RTX 50 Series GPUs\u2019 G7 memory?", "answer": "1.8 terabytes per second", "difficulty": "easy", "avg_score": "100.0", "worst_score": "100", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "The memory bandwidth of the GeForce RTX 50 Series GPUs' G7 memory is 1.8 terabytes per second.", "model": "gpt-4o"}, {"question": "Name one of the AI models mentioned that can generate 3D images from textual prompts.", "answer": "Flux (an image generation NeMo)", "difficulty": "easy", "avg_score": "90.0", "worst_score": "85", "best_score": "95", "acceptable_score": "100.00%", "best_answer": "One of the AI models mentioned that can generate 3D images from textual prompts is the NVIDIA NeMo model called \"Flux.\"", "model": "gpt-4o"}, {"question": "Which NVIDIA platform is used to help develop domain-specific AI agents for enterprise use?", "answer": "NVIDIA NeMo", "difficulty": "easy", "avg_score": "99.0", "worst_score": "95", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "The NVIDIA platform used to help develop domain-specific AI agents for enterprise use is the NVIDIA NeMo framework.", "model": "gpt-4o"}, {"question": "What major change did Google's Transformer bring to AI according to the keynote?", "answer": "It completely changed the landscape for artificial intelligence and computing", "difficulty": "easy", "avg_score": "94.0", "worst_score": "90", "best_score": "95", "acceptable_score": "100.00%", "best_answer": "Google's Transformer, released as BERT in 2018, fundamentally changed the landscape for artificial intelligence and computing altogether. It marked a significant leap in AI by enabling machine learning models to understand and generate human-like text, leading to rapid advancements in AI capabilities. The introduction of Transformers initiated a new era in AI development, transforming it from perception-based tasks to more complex reasoning, planning, and generative tasks.", "model": "gpt-4o"}, {"question": "What is the code name of NVIDIA\u2019s new world foundation model for physical AI?", "answer": "NVIDIA Cosmos", "difficulty": "easy", "avg_score": "100.0", "worst_score": "100", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "The code name of NVIDIA\u2019s new world foundation model for physical AI is NVIDIA Cosmos.", "model": "gpt-4o"}, {"question": "Which technology helps reduce the computational load by generating unrendered pixels using AI?", "answer": "DLSS (Deep Learning Super Sampling)", "difficulty": "easy", "avg_score": "100.0", "worst_score": "100", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "The technology that helps reduce the computational load by generating unrendered pixels using AI is called DLSS (Deep Learning Super Sampling). It uses artificial intelligence to infer and predict the pixels that are not rendered, thereby reducing the need for extensive computation and improving performance.", "model": "gpt-4o"}, {"question": "How many transistors does the Blackwell GPU in the RTX 50 Series have?", "answer": "92 billion transistors", "difficulty": "medium", "avg_score": "100.0", "worst_score": "100", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "The Blackwell GPU in the RTX 50 Series has 92 billion transistors.", "model": "gpt-4o"}, {"question": "What is the name of NVIDIA\u2019s next-generation robotics computer announced in the keynote?", "answer": "Thor", "difficulty": "medium", "avg_score": "100.0", "worst_score": "100", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "The name of NVIDIA\u2019s next-generation robotics computer announced in the keynote is \"Thor.\"", "model": "gpt-4o"}, {"question": "What is the function of post-training scaling mentioned in the keynote?", "answer": "It involves techniques like reinforcement learning and human feedback to refine AI after its initial training", "difficulty": "medium", "avg_score": "95.0", "worst_score": "95", "best_score": "95", "acceptable_score": "100.00%", "best_answer": "Post-training scaling involves using techniques such as reinforcement learning and human feedback to refine an AI model after its initial training. This process requires a substantial amount of computation and aims to improve the AI's performance by allowing it to fine-tune its skills in specific domains and enhance its reasoning capabilities. The end result of post-training scaling is the development of highly effective and capable models.", "model": "gpt-4o"}, {"question": "Which automotive company did Jensen mention as a new partner for developing next-generation AVs with NVIDIA?", "answer": "Toyota", "difficulty": "medium", "avg_score": "100.0", "worst_score": "100", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "Jensen mentioned that Toyota and NVIDIA are going to partner together to create their next-generation autonomous vehicles (AVs).", "model": "gpt-4o"}, {"question": "What is the main focus of NVIDIA Isaac GrOot in robotics development?", "answer": "It provides tools and workflows for synthetic data generation, imitation learning, and policy training for humanoid robots", "difficulty": "medium", "avg_score": "94.0", "worst_score": "90", "best_score": "95", "acceptable_score": "100.00%", "best_answer": "The main focus of NVIDIA Isaac GrOot in robotics development is to provide a technology platform and elements that accelerate the development of general robotics. This includes enabling the creation of exponentially large data sets for training robots through simulation workflows for imitation learning, which can be generated from a small number of demonstrations. Additionally, it offers humanoid robot developers foundational models, data pipelines, simulation frameworks, and the Thor robotics computer to tackle the challenges associated with developing general-purpose robot models.", "model": "gpt-4o"}, {"question": "What are the three computers that NVIDIA says every robotics company will need?", "answer": "A DGX for training AI models, Omniverse/Cosmos for simulation, and an AGX (like Thor) in the robot or autonomous system", "difficulty": "medium", "avg_score": "94.0", "worst_score": "90", "best_score": "95", "acceptable_score": "100.00%", "best_answer": "The three computers that NVIDIA says every robotics company will need are: NVIDIA DGX for training AI models, Omniverse for testing, driving, and generating synthetic data, and DRIVE AGX, a supercomputer that resides in the car or robot.", "model": "gpt-4o"}, {"question": "Why is synthetic data so crucial for training autonomous vehicles according to the keynote?", "answer": "Real-world data is limited and costly to capture; synthetic data can amplify edge cases and help train at massive scale", "difficulty": "medium", "avg_score": "95.0", "worst_score": "95", "best_score": "95", "acceptable_score": "100.00%", "best_answer": "Synthetic data is crucial for training autonomous vehicles because it allows for the generation of an enormous amount of diverse and high-fidelity driving scenarios, which are essential given the limitations of real-world data. Using platforms like NVIDIA Omniverse and Cosmos, synthetic data can be scaled to create billions of effective miles from recorded drives, enhancing the training data by orders of magnitude. This approach addresses edge-case scenarios and ensures that AI models are well-equipped to handle various driving conditions, contributing to safer and more advanced autonomous vehicles.", "model": "gpt-4o"}, {"question": "What kind of new AI era does Jensen predict is approaching for enterprise applications?", "answer": "Agentic AI, where multiple AI models collaborate, plan, and take actions on behalf of users", "difficulty": "medium", "avg_score": "95.0", "worst_score": "95", "best_score": "95", "acceptable_score": "100.00%", "best_answer": "Jensen predicts the arrival of the \"Agentic AI\" era for enterprise applications, where AI agents will be capable of perceiving, reasoning, planning, and acting. These AI agents are expected to become the new digital workforce, working alongside humans and revolutionizing how tasks are accomplished across various industries. This development is anticipated to open up multi-trillion-dollar opportunities in robotics and AI-driven enterprise solutions.", "model": "gpt-4o"}, {"question": "Which core idea makes Omniverse critical for physically accurate simulation?", "answer": "It is a physics-principled simulation platform, grounded in real-world principles like friction, lighting, and object permanence", "difficulty": "medium", "avg_score": "90.0", "worst_score": "85", "best_score": "95", "acceptable_score": "100.00%", "best_answer": "The core idea that makes Omniverse critical for physically accurate simulation is its foundation as a physics-principled simulation system. This grounding provides the \"ground truth\" necessary to ensure that the synthetic data and scenarios generated within the Omniverse are physically accurate and realistic, reducing the gap between simulation and real-world applications. By integrating with Cosmos, Omniverse enables the creation of a multiverse of physically grounded, photorealistic scenarios crucial for training AI models and robotics systems.", "model": "gpt-4o"}, {"question": "What is NVIDIA\u2019s stated reason for making Llama 2 NeoTron models available?", "answer": "To provide enterprise-focused models with improved fine-tuning and performance for domains like chat, instruction, and retrieval", "difficulty": "hard", "avg_score": "87.0", "worst_score": "85", "best_score": "90", "acceptable_score": "100.00%", "best_answer": "NVIDIA's stated reason for making the Llama 2 NeoTron models available is to improve the Llama models for enterprise use by fine-tuning them with NVIDIA's expertise and capabilities, making them open-source for modification. This enables the ecosystem to take advantage of these models by integrating them into software packages and creating AI agents that can be deployed across various platforms and industries.", "model": "gpt-4o"}, {"question": "Name two techniques mentioned that allow AI models to refine themselves after initial training.", "answer": "Reinforcement learning with human feedback and synthetic data generation", "difficulty": "hard", "avg_score": "82.0", "worst_score": "80", "best_score": "85", "acceptable_score": "100.00%", "best_answer": "Two techniques that allow AI models to refine themselves after initial training are reinforcement learning and test-time scaling. Reinforcement learning involves the AI receiving feedback and iteratively improving its performance by learning from past attempts. Test-time scaling involves adjusting computational resources during inference to produce better answers.", "model": "gpt-4o"}, {"question": "How much performance gain, in terms of perf per watt, does the Blackwell-based datacenter system have over the previous generation?", "answer": "It is roughly four times more performance per watt than the previous generation", "difficulty": "hard", "avg_score": "100.0", "worst_score": "100", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "The Blackwell-based datacenter system has a performance gain of four times the perf per watt over the previous generation.", "model": "gpt-4o"}, {"question": "Approximately how large is the total memory in NVIDIA\u2019s \u2018giant chip\u2019 multi-GPU configuration described in the keynote?", "answer": "About 14 terabytes of memory", "difficulty": "hard", "avg_score": "100.0", "worst_score": "100", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "The total memory in NVIDIA's 'giant chip' multi-GPU configuration described in the keynote is 14 terabytes of HBM memory.", "model": "gpt-4o"}, {"question": "Which industry does Jensen predict will be the first multi-trillion-dollar robotics market?", "answer": "Autonomous vehicles (AVs)", "difficulty": "hard", "avg_score": "100.0", "worst_score": "100", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "Jensen predicts that the autonomous vehicle industry will likely be the first multi-trillion-dollar robotics market.", "model": "gpt-4o"}, {"question": "What does test-time scaling in AI primarily involve?", "answer": "Allocating more or different amounts of compute during inference, often for multi-step reasoning or chain-of-thought processes", "difficulty": "hard", "avg_score": "93.0", "worst_score": "90", "best_score": "95", "acceptable_score": "100.00%", "best_answer": "Test-time scaling in AI primarily involves adjusting the amount of computational resources allocated during the inference stage to produce answers, rather than improving the AI model's parameters. This allows the AI to dynamically decide how much computation to use to achieve optimal results, focusing on efficiency and effectiveness in generating responses.", "model": "gpt-4o"}, {"question": "What is the significance of NVIDIA\u2019s Drive OS reaching ASIL D certification?", "answer": "It is the highest functional safety standard, making NVIDIA\u2019s AI computer software-defined yet safety-certified for cars", "difficulty": "hard", "avg_score": "95.0", "worst_score": "95", "best_score": "95", "acceptable_score": "100.00%", "best_answer": "The significance of NVIDIA\u2019s Drive OS reaching ASIL D certification is that it represents the highest standard of functional safety for automobiles. This achievement marks NVIDIA's Drive OS as the first software-defined, programmable AI computer to be certified to this level, demonstrating a strong commitment to safety in autonomous vehicle technology. Such certification assures that the system meets rigorous safety requirements, which is critical for its application in the automotive industry.", "model": "gpt-4o"}, {"question": "Which specific memory technology is used in the Grace Hopper-based \u2018smallest chip\u2019 for the newly unveiled Project Digits system?", "answer": "HBM (High Bandwidth Memory), connected with chip-to-chip NVLink", "difficulty": "hard", "avg_score": "85.0", "worst_score": "85", "best_score": "85", "acceptable_score": "100.00%", "best_answer": "The specific memory technology used in the Grace Hopper-based 'smallest chip' for the newly unveiled Project Digits system is HBM (High Bandwidth Memory).", "model": "gpt-4o"}, {"question": "How many hours of video was Cosmos trained on to understand physical dynamics?", "answer": "20 million hours of video", "difficulty": "hard", "avg_score": "100.0", "worst_score": "100", "best_score": "100", "acceptable_score": "100.00%", "best_answer": "NVIDIA Cosmos was trained on 20 million hours of video to understand physical dynamics.", "model": "gpt-4o"}, {"question": "Why is WSL2 (Windows Subsystem for Linux 2) important for AI on Windows PCs according to the keynote?", "answer": "It gives direct access to CUDA out of the box, enabling cloud-native AI workflows and NVIDIA's entire AI software stack on Windows", "difficulty": "hard", "avg_score": "93.0", "worst_score": "90", "best_score": "95", "acceptable_score": "100.00%", "best_answer": "WSL2 (Windows Subsystem for Linux 2) is important for AI on Windows PCs because it transforms Windows PCs into a first-class platform for AI development by supporting CUDA perfectly out of the box, enabling access to bare metal, and optimizing for cloud-native applications. This makes it possible to run a variety of AI models, including those for vision, language, and digital humans, directly on Windows PCs, enhancing the capabilities for engineers and developers. It allows Windows PCs to become world-class AI PCs, making AI development more accessible and efficient.", "model": "gpt-4o"}
]