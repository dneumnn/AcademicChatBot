import logging
from neo4j import GraphDatabase
from langchain_ollama import ChatOllama
from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI

from ..constants.env import NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD

graphstore = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))

def get_full_graph_information():
    with graphstore.session() as session:
        # Get all nodes and relationships
        result = session.run("""
            MATCH (n)
            OPTIONAL MATCH (n)-[r]->(m)
            RETURN collect(distinct {
                node: n,
                type: labels(n)[0],
                properties: properties(n)
            }) as nodes,
            collect(distinct {
                start: startNode(r),
                type: type(r),
                end: endNode(r),
                properties: properties(r)
            }) as relationships
        """)
        result_data = result.single()
        print("Nodes:", result_data["nodes"])
        print("Relationships:", result_data["relationships"])
        return result_data

def question_to_graphdb(question: str, llm: ChatOpenAI | ChatOllama | ChatGoogleGenerativeAI, logger: logging.Logger, mode: str) -> str:
    try:
        with graphstore.session() as session:
            schema = session.run("""
                CALL db.schema.visualization()
                YIELD nodes, relationships
                RETURN nodes, relationships
            """).single()

            samples = session.run("""
                MATCH (entity)
                WITH labels(entity) as labels, count(entity) as count
                RETURN labels, count
                LIMIT 150
            """).data()

            sample_names = session.run("""
                MATCH (entity)
                RETURN entity.name
                LIMIT 500
            """).data()

            sample_relationships = session.run("""
                MATCH (entity)-[r]->(other)
                RETURN type(r), count(r)
                LIMIT 150
            """).data()

            properties = session.run("""
                MATCH (entity)
                RETURN properties(entity)
                LIMIT 10
            """).data()

            excerpt = session.run("""
                MATCH (entity)
                RETURN entity
                LIMIT 3000
            """).data()

            prompt = f"""
            MOST IMPORTANT: MAKE THE CYPHER QUERY WORK WITH THE GRAPH. NO MATTER WHAT, RETURN A WORKING QUERY.
            ONLY USE THE name AND text ATTRIBUTES TO ACTIVELY QUERY ENTITIES. ONLY USE KOWN LINKS BETWEEN NODES.
            You can also use the contains method on the text attribute of nodes.

            Given the following Neo4j graph structure:

            =================================
            Node types and counts: {samples}
            Schema: {schema}
            Sample entity names: {sample_names}
            Sample relationships: {sample_relationships}
            These are the properties of the nodes: {properties}
            Excerpt of the graph: {excerpt}
            =================================

            Convert this question to a Cypher query that will answer it:
            {question}
            The query might need to be converted completely, use the information you know about the graph to try and answer the question.
            Do not try to convert the question 1:1 to a Cypher query, try to obtain insights from the graph.

            Return only the Cypher query, no explanation. No Markdown. No code blocks.
            The result of the query will be used to answer the question.
            The cypher query should try to obtain insights from the graph.
            Keep it simple, priority is that the query is correct and works.

            The query should return relevant entities.
            """

            cypher_query = llm.invoke(prompt)

            cypher_query_content = cypher_query.content

            logger.info(f"Cypher query: {cypher_query_content}")

            result = session.run(cypher_query_content)
            data = result.data()

            metadata = []

            logger.info(f"Result: {data}")

            if mode == "fast":
                return (str(data), metadata)

            answer_prompt = f"""
            The following is the result of a Cypher query: {data}
            Answer the question: {question}

            This was the Cypher query used to generate the result: {cypher_query_content}

            Use only the provided information to answer the question. Do not use quotations.
            The answer is the result of a query generated by the same question, so assume the result is relevant.
            If you do not know the answer, mention the missing context.
            Make the sentence feel human. Add pronouns and other natural language elements if needed.

            DO NOT MENTION ANYTHING ABOUT THE QUERY OR THE GRAPH. JUST TRY TO ANSWER THE QUESTION.
            DO NOT MENTION NODES OR DATA. DO NOT MAKE GUESSES. DO NOT MAKE ASSUMPTIONS.
            IF YOU DO NOT KNOW THE ANSWER, JUST ADMIT IT.
            BE CONCISE.
            """

            answer = llm.invoke(answer_prompt)
            answer_text = answer.content

            logger.info(f"Answer to the neo4j question: {answer_text}")

            return (answer_text, metadata)
    except Exception as e:
        logger.error(f"Error: {e}")
        return ("", [])

if __name__ == "__main__":
    #print(get_full_graph_information())
    llm = ChatOllama(model="llama3.2")
    #llm = ChatOpenAI(model="gpt-4o")

    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)

    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    logger.addHandler(console_handler)

    print(question_to_graphdb("Where is the painting?", llm, logger))
